var documenterSearchIndex = {"docs":
[{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"This page provides a comprehensive reference for all public APIs in TVMFFI.jl.","category":"section"},{"location":"api/#Main-Module","page":"API Reference","title":"Main Module","text":"","category":"section"},{"location":"api/#Version-Information","page":"API Reference","title":"Version Information","text":"","category":"section"},{"location":"api/#Module-System","page":"API Reference","title":"Module System","text":"Functions for loading compiled TVM modules and accessing their contents.\n\nModules represent compiled TVM code that can be loaded from shared libraries or other formats.","category":"section"},{"location":"api/#Tensors-and-Data-Types","page":"API Reference","title":"Tensors & Data Types","text":"Core data structures for efficient data exchange between Julia and TVM. TVMFFI.jl provides both reference-counted tensors (TVMTensor) and lightweight views (TensorView) for different use cases.","category":"section"},{"location":"api/#Device-Management","page":"API Reference","title":"Device Management","text":"Functions for creating and working with TVM devices. TVM supports multiple device types including CPU, CUDA, Metal, ROCm, and OpenCL.","category":"section"},{"location":"api/#GPU-Support","page":"API Reference","title":"GPU Support","text":"Utilities for detecting and working with GPU backends. TVMFFI.jl provides automatic GPU detection and optimized paths for CUDA, Metal, and ROCm.","category":"section"},{"location":"api/#Core-Types","page":"API Reference","title":"Core Types","text":"Main types exported by TVMFFI.jl for working with TVM objects, functions, and modules.","category":"section"},{"location":"api/#Object-Registration","page":"API Reference","title":"Object Registration","text":"Macros for registering Julia types as TVM objects.\n\n","category":"section"},{"location":"api/#Advanced-API","page":"API Reference","title":"Advanced API","text":"These APIs are available but not exported by default. Use TVMFFI.xxx to access them. They provide lower-level control and introspection capabilities.","category":"section"},{"location":"api/#Low-Level-Types","page":"API Reference","title":"Low-Level Types","text":"Primitive types and structures that map directly to TVM's C API.","category":"section"},{"location":"api/#Any-Containers-(Internal)","page":"API Reference","title":"Any Containers (Internal)","text":"Types for handling TVM's dynamic TVMValue and TVMValue* types. These are used internally for type-erased value passing.","category":"section"},{"location":"api/#Object-Registration-(Advanced)","page":"API Reference","title":"Object Registration (Advanced)","text":"Advanced macros and functions for registering Julia types as TVM objects and managing the type system.","category":"section"},{"location":"api/#Reflection-API","page":"API Reference","title":"Reflection API","text":"Functions for runtime introspection of TVM objects, including field access, method discovery, and type information.","category":"section"},{"location":"api/#Module-Introspection","page":"API Reference","title":"Module Introspection","text":"Functions for examining compiled TVM modules, including source inspection and capability queries.","category":"section"},{"location":"api/#Internal-Utilities","page":"API Reference","title":"Internal Utilities","text":"Helper functions used internally by TVMFFI.jl for error handling, type conversion, and debugging.","category":"section"},{"location":"api/#Low-Level-C-Bindings","page":"API Reference","title":"Low-Level C Bindings","text":"Direct bindings to the TVM C API functions. These are automatically generated and provide the foundation for the higher-level Julia APIs.","category":"section"},{"location":"api/#TVMFFI","page":"API Reference","title":"TVMFFI","text":"TVMFFI\n\nJulia bindings for TVM FFI (Foreign Function Interface).\n\nThis package provides a Julia interface to TVM's C API, enabling machine learning model compilation and execution from Julia.\n\nCore Types\n\nDLDevice: Device abstraction (CPU, CUDA, etc.)\nDLDataType: Data type descriptor\nTVMError: Error handling\nTVMString: ABI-stable string type\nTVMFunction: Function objects\nTVMTensor: N-dimensional array type\n\nDesign Philosophy\n\nDirect C API calls via ccall (no intermediate layer)\nJulia's GC manages object lifetimes via finalizers\nSimple, clear abstractions without over-engineering\n\n\n\n\n\n","category":"module"},{"location":"api/#TVMFFI.tvm_ffi_version","page":"API Reference","title":"TVMFFI.tvm_ffi_version","text":"tvm_ffi_version() -> VersionNumber\n\nGet the TVM FFI version as a Julia VersionNumber.\n\nThis function queries the C API for version information and converts it to Julia's standard version type for easy comparison and display.\n\nExamples\n\njulia> v = tvm_ffi_version()\nv\"0.1.2\"\n\njulia> v >= v\"0.1.0\"\ntrue\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.load_module","page":"API Reference","title":"TVMFFI.load_module","text":"load_module(path::AbstractString) -> TVMModule\n\nLoad a compiled TVM module from file.\n\nExample\n\nmod = load_module(\"build/add_one_cpu.so\")\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.get_function","page":"API Reference","title":"TVMFFI.get_function","text":"get_function(mod::TVMModule, name, query_imports=true) -> Union{TVMFunction, Nothing}\n\nGet a function from the module by name.\n\nReturns nothing if function not found.\n\nExample\n\nmod = load_module(\"build/add_one_cpu.so\")\nadd_one = get_function(mod, \"add_one_cpu\")\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.system_lib","page":"API Reference","title":"TVMFFI.system_lib","text":"system_lib(symbol_prefix::AbstractString = \"\") -> TVMModule\n\nGet the system library module containing statically linked symbols.\n\nThe system library contains symbols that are registered via the C API during static initialization. This is useful for:\n\nAccessing statically compiled TVM modules\nTesting with symbols registered at compile time\nEmbedded systems without dynamic loading\n\nArguments\n\nsymbol_prefix: Optional prefix for symbol filtering (default: \"\")\n\nExamples\n\n# Get the system library\nmod = system_lib()\n\n# With prefix filtering\ntest_mod = system_lib(\"testing.\")  # Only symbols prefixed with \"__tvm_ffi_testing.\"\n\nSee Also\n\nPython equivalent: tvm_ffi.system_lib() Rust equivalent: SystemLib::new()\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.get_global_func","page":"API Reference","title":"TVMFFI.get_global_func","text":"get_global_func(name::AbstractString) -> Union{TVMFunction, Nothing}\n\nGet a global function by name.\n\nArguments\n\nname::AbstractString: The name of the global function\n\nReturns\n\nTVMFunction if the function exists\nnothing if the function does not exist\n\nExamples\n\nfunc = get_global_func(\"my_custom_function\")\nif func !== nothing\n    result = func(arg1, arg2)\nend\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.register_global_func","page":"API Reference","title":"TVMFFI.register_global_func","text":"register_global_func(name::AbstractString, func::Function; override::Bool=false)\n\nRegister a Julia function as a global TVM function.\n\nArguments\n\nname: Global function name (e.g., \"mypkg.myfunc\")\nfunc: Julia function to register\noverride: Whether to override existing function\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.TVMTensor","page":"API Reference","title":"TVMFFI.TVMTensor","text":"TVMTensor\n\nTVM tensor wrapper with automatic memory management.\n\nProvides accessors for shape, dtype, and device information.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TensorView","page":"API Reference","title":"TVMFFI.TensorView","text":"TensorView{T, S, N}\n\nLightweight DLTensor wrapper for Julia ↔ TVM tensor exchange.\n\nUsed for:\n\nJulia → TVM: Wrap Julia array as DLTensor for passing to TVM functions\nInternal: Temporary view during to_dlmanaged_tensor\n\nType Parameters\n\nT: Element type (Float32, Int64, etc.)\nS: Source type (Array, CuArray, or Nothing)\nN: Number of dimensions (compile-time constant for zero-alloc shape/strides)\n\nFields\n\ndltensor::DLTensor: DLPack tensor structure (pointers point to shape/strides)\n_shape::NTuple{N, Int64}: Shape tuple (inline storage, zero allocation)\n_strides::NTuple{N, Int64}: Strides tuple (inline storage, zero allocation)\nsource::S: Source array (kept alive to prevent GC)\nownership::TensorOwnership: Who manages the underlying data\n\nPerformance\n\nShape and strides are stored inline as NTuple, avoiding heap allocation. This saves ~144 bytes per TensorView creation compared to Vector storage.\n\nExample\n\narr = rand(Float32, 3, 4)\nview = TensorView(arr)  # JuliaOwned, source = arr, N=2\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.from_dlpack","page":"API Reference","title":"TVMFFI.from_dlpack","text":"from_dlpack(tensor::TVMTensor) -> AbstractArray\n\nConvert TVMTensor to Julia array (zero-copy).\n\nThe returned array shares memory with the TVMTensor. The TVMTensor is kept alive automatically until the array is garbage collected.\n\nExample\n\ntensor = some_tvm_function()\narr = from_dlpack(tensor)  # Zero-copy, shares memory\n\nSee also\n\nTVMTensor: Create TVMTensor from Julia array\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.dldevice","page":"API Reference","title":"TVMFFI.dldevice","text":"dldevice(arr) -> DLDevice\n\nGet the DLPack device for an array.\n\nDefault implementation returns CPU device. GPU extensions override this for their specific array types (CuArray, MtlArray, ROCArray, etc.).\n\nReturns\n\nDLDevice(kDLCPU, 0) for CPU arrays (default)\nDLDevice(kDLCUDA, device_id) for CUDA arrays\nDLDevice(kDLMetal, device_id) for Metal arrays\nDLDevice(kDLROCM, device_id) for ROCm arrays\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.shape","page":"API Reference","title":"TVMFFI.shape","text":"shape(tensor::TVMTensor) -> Vector{Int64}\n\nGet the shape of the tensor as a vector.\n\nNote\n\nJulia arrays typically use size() which returns a tuple. This function returns a vector for compatibility with some use cases.\n\n\n\n\n\nGet the shape as a Vector (for compatibility).\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.dtype","page":"API Reference","title":"TVMFFI.dtype","text":"dtype(tensor::TVMTensor) -> DLDataType\n\nGet the data type of the tensor.\n\n\n\n\n\nGet the dtype of a TensorView.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.device","page":"API Reference","title":"TVMFFI.device","text":"device(tensor::TVMTensor) -> DLDevice\n\nGet the device of the tensor.\n\n\n\n\n\nGet the device of a TensorView.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.DLDataType","page":"API Reference","title":"TVMFFI.DLDataType","text":"DLDataType\n\nRe-export from LibTVMFFI for convenience. Represents a data type in DLPack format.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.DLDevice","page":"API Reference","title":"TVMFFI.DLDevice","text":"DLDevice\n\nRe-export from LibTVMFFI for convenience. Represents a device (CPU, GPU, etc.) and device ID.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.cpu","page":"API Reference","title":"TVMFFI.cpu","text":"cpu(id::Integer=0) -> DLDevice\n\nCreate a CPU device context.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.cuda","page":"API Reference","title":"TVMFFI.cuda","text":"cuda(id::Integer=0) -> DLDevice\n\nCreate a CUDA device context.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.opencl","page":"API Reference","title":"TVMFFI.opencl","text":"opencl(id::Integer=0) -> DLDevice\n\nCreate an OpenCL device context.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.vulkan","page":"API Reference","title":"TVMFFI.vulkan","text":"vulkan(id::Integer=0) -> DLDevice\n\nCreate a Vulkan device context.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.metal","page":"API Reference","title":"TVMFFI.metal","text":"metal(id::Integer=0) -> DLDevice\n\nCreate a Metal device context.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.rocm","page":"API Reference","title":"TVMFFI.rocm","text":"rocm(id::Integer=0) -> DLDevice\n\nCreate a ROCm device context.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.supports_gpu_backend","page":"API Reference","title":"TVMFFI.supports_gpu_backend","text":"supports_gpu_backend(backend::Symbol) -> Bool\n\nCheck if a specific GPU backend is available.\n\nArguments\n\nbackend::Symbol: Backend to check (:CUDA, :ROCm, :Metal, :oneAPI)\n\nReturns\n\nBool: Whether the backend package is loaded\n\nExamples\n\nif supports_gpu_backend(:CUDA)\n    println(\"CUDA is available!\")\nend\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.list_available_gpu_backends","page":"API Reference","title":"TVMFFI.list_available_gpu_backends","text":"list_available_gpu_backends() -> Vector{Symbol}\n\nList all available and functional GPU backends.\n\nReturns\n\nVector{Symbol}: List of available backends\n\nExamples\n\nbackends = list_available_gpu_backends()\nprintln(\"Available GPU backends: \", backends)\n# Output: [:CUDA, :ROCm]  (depending on system)\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.TVMFunction","page":"API Reference","title":"TVMFFI.TVMFunction","text":"TVMFunction\n\nWrapper for TVM function objects with automatic argument conversion.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMModule","page":"API Reference","title":"TVMFFI.TVMModule","text":"TVMModule\n\nWrapper for TVM module objects.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMError","page":"API Reference","title":"TVMFFI.TVMError","text":"TVMError <: Exception\n\nTVM FFI error type.\n\nFields\n\nkind::String: Error kind (ValueError, TypeError, etc.)\nmessage::String: Error message\nbacktrace::String: Stack backtrace\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMErrorKind","page":"API Reference","title":"TVMFFI.TVMErrorKind","text":"TVMErrorKind\n\nError kind wrapper. Simply wraps a string for clarity.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.@register_object","page":"API Reference","title":"TVMFFI.@register_object","text":"@register_object type_key struct TypeName [<: ParentType] ... end\n\nRegister a Julia struct as a TVM object type with automatic memory management.\n\nThis macro generates:\n\nA mutable struct with a handle field for the TVM object handle\nA constructor that properly manages reference counting\nA finalizer for automatic cleanup\nType index methods for runtime type queries\n\nArguments\n\ntype_key: The TVM type key (e.g., \"testing.MyObject\")\nThe struct definition (fields are for documentation only; actual field access requires TVM reflection API support in C++)\n\nExamples\n\n# Basic usage - wrap existing TVM type\n@register_object \"ffi.Module\" struct Module end\n\n# With parent type annotation (for documentation)\n@register_object \"testing.TestObject\" struct TestObject <: TVMObjectBase\n    v_i64::Int64   # Field declaration (actual access via TVM)\n    v_f64::Float64\nend\n\n# After registration, create instances from handles:\nobj = TestObject(handle; borrowed=false)  # Take ownership\nobj = TestObject(handle; borrowed=true)   # Copy reference\n\nNotes\n\nThe type key must be registered on the C++ side first\nField declarations are informational; actual field access depends on TVM's reflection API being available for that type\nFor types with __ffi_init__, use ffi_init(T, args...) or T(args...) to create instances\n\nSee also: register_object, get_type_index, type_index\n\n\n\n\n\n","category":"macro"},{"location":"api/#TVMFFI.type_index","page":"API Reference","title":"TVMFFI.type_index","text":"type_index(obj) -> Int32\ntype_index(T::Type) -> Int32\n\nGet the runtime type index of an object or the registered type index for a type.\n\nFor objects, returns the actual runtime type index from the C++ object header. For types, returns the type index allocated during registration.\n\nExamples\n\nobj = TestCxxClassBase(42, 10)\ntype_index(obj)              # Runtime index (e.g., 133)\ntype_index(TestCxxClassBase) # Same as above for registered types\ntype_index(TVMFunction)      # Built-in type index (68)\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.type_key","page":"API Reference","title":"TVMFFI.type_key","text":"type_key(T::Type) -> String\n\nGet the type key for a registered Julia type. Returns nothing if not registered.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.DLTensor","page":"API Reference","title":"TVMFFI.DLTensor","text":"DLTensor\n\nDLPack tensor structure (from dlpack.h). This is a C-compatible struct representing a multi-dimensional array.\n\nNote on GPU Pointers\n\nFor GPU arrays (CuArray, ROCArray, etc.), the data field contains a GPU device pointer, not a CPU pointer. We use UInt64 to store the pointer value and reinterpret it as needed, since GPU pointers can't be directly converted to Ptr{Cvoid}.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.DLDeviceType","page":"API Reference","title":"TVMFFI.DLDeviceType","text":"DLDeviceType\n\nDevice type enum (CPU, CUDA, etc.) matching DLPack specification.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.DLDataTypeCode","page":"API Reference","title":"TVMFFI.DLDataTypeCode","text":"DLDataTypeCode\n\nData type code enum (Int, UInt, Float, etc.) matching DLPack specification.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMObject","page":"API Reference","title":"TVMFFI.TVMObject","text":"TVMObject\n\nBase wrapper for TVM FFI object handles with automatic memory management.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMString","page":"API Reference","title":"TVMFFI.TVMString","text":"TVMString\n\nTVM ABI-stable string type.\n\nWraps TVM FFI string representation with automatic memory management. Small strings (≤7 bytes) are stored inline, larger strings are heap-allocated.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMBytes","page":"API Reference","title":"TVMFFI.TVMBytes","text":"TVMBytes\n\nTVM ABI-stable bytes type (for binary data).\n\nSimilar to TVMString but for arbitrary binary data.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMAny","page":"API Reference","title":"TVMFFI.TVMAny","text":"TVMAny\n\nAn owned TVM value. Manages reference count for object types.\n\nUse this type when:\n\nReceiving function return values (C transfers ownership)\nStoring values beyond the current scope\nConverting from TVMAnyView to keep the value alive\n\nLifecycle\n\nConstruction: Does NOT IncRef (assumes ownership transferred)\nDestruction: DecRef for object types via finalizer\n\nExample\n\n# Function return - take ownership directly\nresult_any = TVMAny(raw_result)\n\n# From borrowed view - uses TVMFFIAnyViewToOwnedAny\nowned = TVMAny(view::TVMAnyView)\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.TVMAnyView","page":"API Reference","title":"TVMFFI.TVMAnyView","text":"TVMAnyView\n\nA borrowed view into a TVM value. Does NOT manage reference counts.\n\nUse this type when:\n\nReceiving callback arguments from C (C owns the reference)\nTemporarily accessing values without taking ownership\n\nWarning\n\nThe view is only valid while the underlying C reference is alive. Do NOT store TVMAnyView beyond the current scope.\n\nExample\n\nfunction my_callback(args_ptr::Ptr{LibTVMFFI.TVMFFIAny}, num_args::Int)\n    for i in 1:num_args\n        # Create view - does not IncRef\n        view = TVMAnyView(unsafe_load(args_ptr, i))\n        \n        # Convert to owned value if needed beyond this scope\n        owned = TVMAny(view)\n    end\nend\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.take_value","page":"API Reference","title":"TVMFFI.take_value","text":"take_value(any::TVMAny) -> Any\n\nExtract the Julia value from an owned TVMAny, consuming ownership.\n\nFor object types, the returned wrapper (TVMFunction, TVMObject, etc.) takes over reference management. The TVMAny is invalidated after this call.\n\nExample\n\nresult = func(x)  # Returns TVMAny\nvalue = take_value(result)  # Extracts and transfers ownership\n# result is now invalidated\n\nImplementation Note\n\nAfter take_value, the TVMAny's data is cleared to prevent double-free. The finalizer will no longer DecRef the object.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.copy_value","page":"API Reference","title":"TVMFFI.copy_value","text":"copy_value(view::TVMAnyView) -> Any\n\nExtract the Julia value from a borrowed view, copying if necessary.\n\nFor object types, this increments the reference count so the returned value is independent of the original view's lifetime.\n\nExample\n\nfunction callback(view::TVMAnyView)\n    value = copy_value(view)  # Safe to use after callback returns\n    return value\nend\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.raw_data","page":"API Reference","title":"TVMFFI.raw_data","text":"raw_data(any::TVMAny) -> LibTVMFFI.TVMFFIAny\n\nGet the raw TVMFFIAny data (internal use only).\n\n\n\n\n\nraw_data(view::TVMAnyView) -> LibTVMFFI.TVMFFIAny\n\nGet the raw TVMFFIAny data (internal use only).\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.register_object","page":"API Reference","title":"TVMFFI.register_object","text":"register_object(type_key::String, T::Type; parent_type_index::Int32 = Int32(64))\n\nRegister a Julia type as a TVM object type.\n\nArguments\n\ntype_key: The type key defined in C++ (e.g., \"tvm.RelayExpr\")\nT: The Julia type to map to this type key\nparent_type_index: Parent type index (default: 64 = ffi.Object)\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.get_type_index","page":"API Reference","title":"TVMFFI.get_type_index","text":"get_type_index(type_key::String) -> Int32\n\nGet the type index for a given type key.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.@register_object_simple","page":"API Reference","title":"TVMFFI.@register_object_simple","text":"@register_object_simple type_key TypeName\n\nA simplified version of @register_object that only registers the type without creating a new struct. Use when you want to manually define the struct.\n\nExample\n\nmutable struct MyCustomObject\n    handle::LibTVMFFI.TVMFFIObjectHandle\n    cached_value::Int  # Custom cached field\n\n    function MyCustomObject(handle; borrowed::Bool)\n        # Custom constructor logic\n        ...\n    end\nend\n\n@register_object_simple \"my.CustomObject\" MyCustomObject\n\n\n\n\n\n","category":"macro"},{"location":"api/#TVMFFI.get_type_info","page":"API Reference","title":"TVMFFI.get_type_info","text":"get_type_info(type_index::Int32) -> Union{LibTVMFFI.TVMFFITypeInfo, Nothing}\n\nGet the type information for a given type index. Returns nothing if the type index is invalid.\n\n\n\n\n\nget_type_info(type_key::String) -> Union{LibTVMFFI.TVMFFITypeInfo, Nothing}\n\nGet the type information for a given type key.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.get_fields","page":"API Reference","title":"TVMFFI.get_fields","text":"get_fields(type_info::LibTVMFFI.TVMFFITypeInfo) -> Vector{FieldInfo}\n\nGet all fields defined for a type.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.get_methods","page":"API Reference","title":"TVMFFI.get_methods","text":"get_methods(type_info::LibTVMFFI.TVMFFITypeInfo) -> Vector{MethodInfo}\n\nGet all methods defined for a type.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.FieldInfo","page":"API Reference","title":"TVMFFI.FieldInfo","text":"FieldInfo\n\nJulia wrapper for TVMFFIFieldInfo with convenient accessors.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.MethodInfo","page":"API Reference","title":"TVMFFI.MethodInfo","text":"MethodInfo\n\nJulia wrapper for TVMFFIMethodInfo with convenient accessors.\n\n\n\n\n\n","category":"type"},{"location":"api/#TVMFFI.get_field_value","page":"API Reference","title":"TVMFFI.get_field_value","text":"get_field_value(obj, field::FieldInfo) -> Any\n\nRead a field value from an object using the reflection getter.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.set_field_value!","page":"API Reference","title":"TVMFFI.set_field_value!","text":"set_field_value!(obj, field::FieldInfo, value) -> Nothing\n\nWrite a field value to an object using the reflection setter.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.call_method","page":"API Reference","title":"TVMFFI.call_method","text":"call_method(obj, method::MethodInfo, args...) -> Any\n\nCall a method on an object. For instance methods, obj is automatically prepended to the arguments.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.get_method_function","page":"API Reference","title":"TVMFFI.get_method_function","text":"get_method_function(method::MethodInfo) -> TVMFunction\n\nGet the TVMFunction for a MethodInfo. Creates a borrowed reference. This function is defined here because it depends on TVMFunction.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.has_ffi_init","page":"API Reference","title":"TVMFFI.has_ffi_init","text":"has_ffi_init(T::Type) -> Bool\n\nCheck if a type has an ffi_init method registered.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.ffi_init","page":"API Reference","title":"TVMFFI.ffi_init","text":"ffi_init(T::Type, args...; kwargs...) -> T\n\nCreate an instance of T using its ffi_init method.\n\nExample\n\n@register_object \"testing.MyClass\" struct MyClass end\n\n# If MyClass has __ffi_init__(v_i64, v_f64), you can call:\nobj = ffi_init(MyClass, 42, 3.14)\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.write_to_file","page":"API Reference","title":"TVMFFI.write_to_file","text":"write_to_file(mod::TVMModule, file_name::AbstractString, format::AbstractString = \"\")\n\nSave a TVM module to a file.\n\nArguments\n\nmod: The TVM module to save\nfile_name: Output file path\nformat: Optional format specifier (e.g., \"so\", \"dll\", \"dylib\")\n\nExamples\n\nmod = load_module(\"my_module.so\")\nwrite_to_file(mod, \"output.so\", \"so\")\n\nSee Also\n\nPython equivalent: mod.save(file_name, fmt)\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.inspect_source","page":"API Reference","title":"TVMFFI.inspect_source","text":"inspect_source(mod::TVMModule, format::AbstractString = \"\") -> String\n\nInspect the source code of a module for debugging.\n\nArguments\n\nmod: The TVM module to inspect\nformat: Optional format specifier (e.g., \"ll\" for LLVM IR, \"asm\" for assembly)\n\nExamples\n\nmod = load_module(\"my_module.so\")\nsource = inspect_source(mod, \"ll\")\nprintln(source)\n\nSee Also\n\nPython equivalent: mod.get_source(fmt)\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.get_module_kind","page":"API Reference","title":"TVMFFI.get_module_kind","text":"get_module_kind(mod::TVMModule) -> String\n\nGet the kind/type of a module (e.g., \"llvm\", \"cuda\", \"c\").\n\nExamples\n\nmod = load_module(\"my_module.so\")\nkind = get_module_kind(mod)\nprintln(\"Module kind: \", kind)\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.implements_function","page":"API Reference","title":"TVMFFI.implements_function","text":"implements_function(mod::TVMModule, name::AbstractString, query_imports::Bool = true) -> Bool\n\nCheck if a module implements a specific function.\n\nExamples\n\nmod = load_module(\"my_module.so\")\nif implements_function(mod, \"my_func\")\n    println(\"Function exists!\")\nend\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.check_call","page":"API Reference","title":"TVMFFI.check_call","text":"check_call(ret::Integer)\n\nCheck C API return code and throw TVMError if non-zero.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.dtype_to_julia_type","page":"API Reference","title":"TVMFFI.dtype_to_julia_type","text":"dtype_to_julia_type(dtype::DLDataType) -> Type\n\nConvert DLDataType to corresponding Julia type.\n\nExamples\n\ndt = DLDataType(Float32)\nT = dtype_to_julia_type(dt)  # Returns Float32\n\ndt2 = DLDataType(\"int64\")\nT2 = dtype_to_julia_type(dt2)  # Returns Int64\n\nSupported Types\n\nFloat: Float16, Float32, Float64\nInt: Int8, Int16, Int32, Int64\nUInt: UInt8, UInt16, UInt32, UInt64\nBool\n\nThrows\n\nThrows an error for unsupported dtype codes or bit widths.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.print_gpu_info","page":"API Reference","title":"TVMFFI.print_gpu_info","text":"print_gpu_info()\n\nPrint information about available GPU backends and devices.\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.gpu_array_info","page":"API Reference","title":"TVMFFI.gpu_array_info","text":"gpu_array_info(arr)\n\nPrint diagnostic information about a GPU array.\n\nExample\n\nusing CUDA\nx = CUDA.CuArray(Float32[1, 2, 3])\ngpu_array_info(x)\n# Output:\n#   Backend: CUDA\n#   Device: 0\n#   Type: Float32\n#   Shape: (3,)\n#   Pointer: 0x...\n\n\n\n\n\n","category":"function"},{"location":"api/#TVMFFI.LibTVMFFI","page":"API Reference","title":"TVMFFI.LibTVMFFI","text":"LibTVMFFI\n\nLow-level C API bindings for TVM FFI.\n\nThis module provides direct Julia bindings to the TVM FFI C API. All functions follow the naming convention from c_api.h.\n\nDesign Notes\n\nUses ccall for direct C function invocation\nMatches C struct layouts exactly with Julia struct definitions\nNo intermediate abstractions - keep it simple and direct\n\n\n\n\n\n","category":"module"},{"location":"#TVMFFI.jl","page":"Home","title":"TVMFFI.jl","text":"(Image: Dev) (Image: Build Status) (Image: Coverage)\n\nJulia bindings for the TVM FFI (Foreign Function Interface).","category":"section"},{"location":"#Features","page":"Home","title":"Features","text":"TVMFFI.jl provides a complete, idiomatic Julia interface to TVM's C API:","category":"section"},{"location":"#Core-Functionality","page":"Home","title":"✅ Core Functionality","text":"Device Management: CPU, CUDA, OpenCL, Vulkan, Metal, ROCm support\nData Types: Full DLPack integration with automatic type conversion\nZero-Copy TensorViews: Efficient data exchange via TensorView\nError Handling: TVM errors automatically mapped to Julia exceptions\nStrings & Bytes: Small string optimization, heap allocation for large strings","category":"section"},{"location":"#Function-System","page":"Home","title":"✅ Function System","text":"Call TVM Functions: get_global_func() to retrieve and call TVM functions\nRegister Julia Functions: register_global_func() exposes Julia functions to TVM\nAutomatic Conversion: Seamless conversion between Julia and TVM types\nException Safety: Julia errors are properly translated to TVM errors","category":"section"},{"location":"#Object-System","page":"Home","title":"✅ Object System","text":"Type Registration: @register_object macro for wrapping TVM types in Julia\nReflection API: get_type_info(), get_fields(), get_methods() for introspection\nProperty Access: Automatic field/method access via obj.field and obj.method()\nConstructors: Direct TypeName(args...) syntax for types with __ffi_init__\nReference Counting: Automatic memory management via finalizers","category":"section"},{"location":"#Module-System","page":"Home","title":"✅ Module System","text":"Load Modules: load_module() to load compiled TVM modules\nQuery Functions: mod[\"function_name\"] or get_function(mod, name)\nSystem Library: system_lib() for statically linked modules\nModule Introspection: inspect_source(), get_module_kind(), implements_function()\nModule Export: write_to_file() to save compiled modules\nModule Caching: Efficient global function caching","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"using Pkg\nPkg.add(\"TVMFFI\")\n\nOr for the latest development version:\n\nPkg.add(url=\"https://github.com/lucifer1004/TVMFFI.jl\")","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"#Basic-Usage","page":"Home","title":"Basic Usage","text":"using TVMFFI\n\n# Check TVM FFI version\nv = tvm_ffi_version()\nprintln(\"TVM FFI Version: $v\")  # e.g., \"0.1.2\"\n\n# Create devices\ncpu_dev = cpu(0)\ncuda_dev = cuda(0)\n\n# Data types\ndt = DLDataType(Float32)\nprintln(string(dt))  # \"float32\"","category":"section"},{"location":"#Working-with-Arrays-(Zero-Copy)","page":"Home","title":"Working with Arrays (Zero-Copy)","text":"# 1. CPU Arrays\nx = Float32[1, 2, 3, 4, 5]\nholder = TensorView(x)\n\n# 2. GPU Arrays (requires CUDA.jl, Metal.jl, etc.)\n# Automatically detects device type and handles pointers correctly\nusing CUDA\nx_gpu = CuArray(Float32[1, 2, 3])\nholder_gpu = TensorView(x_gpu)\n\n# 3. Call TVM functions\n# Arrays are automatically converted to DLTensor\nresult = some_tvm_func(x_gpu)","category":"section"},{"location":"#Loading-Modules","page":"Home","title":"Loading Modules","text":"# Load a compiled module\nmod = load_module(\"path/to/module.so\")\n\n# Get and call functions\nmy_func = mod[\"function_name\"]\noutput = my_func(input1, input2)","category":"section"},{"location":"#Registering-Julia-Functions","page":"Home","title":"Registering Julia Functions","text":"# Define a Julia function\nfunction my_add(x::Int64, y::Int64)\n    return x + y\nend\n\n# Register it to TVM\nregister_global_func(\"julia.my_add\", my_add)\n\n# Call it from TVM\nfunc = get_global_func(\"julia.my_add\")\nresult = func(Int64(10), Int64(20))  # Returns 30","category":"section"},{"location":"#Working-with-TVM-Objects","page":"Home","title":"Working with TVM Objects","text":"# Register a TVM type for use in Julia\n@register_object \"testing.TestCxxClassBase\" struct TestCxxClassBase end\n\n# Create instances (if the type has __ffi_init__)\nobj = TestCxxClassBase(Int64(42), Int32(10))\n\n# Access fields via reflection\nprintln(obj.v_i64)  # 42\nprintln(obj.v_i32)  # 10\n\n# Modify fields\nobj.v_i64 = Int64(100)\nobj.v_i32 = Int32(20)\n\n# Type introspection\nprintln(type_key(TestCxxClassBase))   # \"testing.TestCxxClassBase\"\nprintln(type_index(TestCxxClassBase)) # Runtime type index","category":"section"},{"location":"#Documentation","page":"Home","title":"Documentation","text":"For full API documentation, see Documentation.\n\nAPI Reference: Complete list of exported functions and types.","category":"section"},{"location":"#Performance","page":"Home","title":"Performance","text":"FFI overhead has been carefully measured. Julia TVMFFI is significantly faster than Python in most scenarios.","category":"section"},{"location":"#Julia-vs-Python-Comparison","page":"Home","title":"Julia vs Python Comparison","text":"Operation Julia Python Speedup\nCPU broadcast add 3 ns 207 ns 67x faster\nTVM NOP (no args) 11 ns 72 ns 6.5x faster\nTVM NOP (pre-converted) 47 ns 72 ns 1.5x faster\nTVM autodlpack (CPU) 30 ns 298 ns 10x faster\nTVM autodlpack (GPU) 580 ns 902 ns 1.6x faster\nCUDA stream query 19 ns 85 ns 4.5x faster","category":"section"},{"location":"#FFI-Overhead-Summary","page":"Home","title":"FFI Overhead Summary","text":"Operation Time Allocations\nTVM func() empty 11 ns 2 (64 B)\nTVM func(Int64) 20 ns 2 (64 B)\nTVM func(Array) autodlpack 30 ns 3 (144 B)\nTVM func(CuArray) autodlpack 200 ns 3 (144 B)\n\nNote: Array calls use zero-copy TensorView - overhead is O(1) regardless of array size.","category":"section"},{"location":"#Overhead-Breakdown","page":"Home","title":"Overhead Breakdown","text":"For a typical scalar function call (~260 ns):\n\nccall + callback dispatch:  232 ns  (89.5%)  ← C-side overhead\nArgs Vector allocation:      12 ns  ( 4.7%)\nTVMAny conversion:            7 ns  ( 2.6%)\nResult Ref allocation:        6 ns  ( 2.5%)\nraw_data extraction:          2 ns  ( 0.7%)\n\nKey insight: 89.5% of overhead is in C-side callback dispatch, not Julia.","category":"section"},{"location":"#Practical-Impact","page":"Home","title":"Practical Impact","text":"Workload FFI Overhead Recommendation\nInference (1ms+) < 0.03% ✅ Negligible\nMicro-ops (1μs) ~20-30% ⚠️ Consider batching\nHot loops (100ns) Dominates ❌ Use raw ccall","category":"section"},{"location":"#Running-Benchmarks","page":"Home","title":"Running Benchmarks","text":"cd benchmarks\njulia --project=. -e 'using Pkg; Pkg.develop(path=\"..\"); Pkg.instantiate()'\njulia --project=. ffi_overhead.jl\njulia --project=. microbenchmarks.jl","category":"section"},{"location":"#Known-Limitation:-GPU-Benchmarking-with-BenchmarkTools","page":"Home","title":"Known Limitation: GPU Benchmarking with BenchmarkTools","text":"@benchmark cannot be used with functions returning new GPU arrays - it will segfault.\n\n# ❌ CRASHES: BenchmarkTools' internal loop discards return values\n@benchmark my_gpu_func($arr)\n\n# ❌ STILL CRASHES: @benchmark only saves first iteration's result\nlocal result\n@benchmark result = my_gpu_func($arr)\n\n# ✅ WORKS: Manual timing with explicit result retention\nlocal result\nfor _ in 1:N\n    result = my_gpu_func(arr)  # Each result kept alive until next iteration\n    CUDA.synchronize()\nend\n\nRoot cause: BenchmarkTools' generated code only saves the first iteration's return value. Subsequent iterations in the internal loop discard results, then gcscrub() triggers GC which crashes in CUDA.jl finalizers.\n\nThis is a known Julia ecosystem issue. For GPU benchmarks, use manual timing or CUDA.@time. See CUDA.jl profiling docs.","category":"section"},{"location":"#Architecture","page":"Home","title":"Architecture","text":"TVMFFI/\n├── src/\n│   ├── LibTVMFFI.jl          # Low-level C bindings\n│   ├── TVMFFI.jl             # Main module\n│   ├── any.jl                # TVMAny/TVMAnyView ownership containers\n│   ├── conversion.jl         # ABI boundary layer (to_tvm_any, take_value, copy_value)\n│   ├── device.jl             # Device abstractions\n│   ├── dtype.jl              # Data type handling\n│   ├── dlpack.jl             # DLPack zero-copy tensor exchange\n│   ├── error.jl              # Error handling\n│   ├── function.jl           # Function calls & registration\n│   ├── gpuarrays_support.jl  # GPU array integration (via DLPack.jl)\n│   ├── module.jl             # Module loading\n│   ├── object.jl             # Object system\n│   ├── string.jl             # String/Bytes types\n│   ├── tensor.jl             # DLTensor support\n│   └── utils.jl              # Utility functions\n├── ext/                      # Package extensions\n│   ├── CUDAExt.jl            # NVIDIA CUDA support\n│   ├── AMDGPUExt.jl          # AMD ROCm support\n│   └── MetalExt.jl           # Apple Metal support\n├── test/                     # Comprehensive test suite\n├── docs/                     # Documentation\n├── examples/                 # Usage examples\n├── benchmarks/               # Performance benchmarks\n├── fixtures/                 # Test fixtures and build files\n├── build/                    # Build artifacts\n├── Project.toml              # Julia package configuration\n├── AGENTS.md                 # Agent guide (technical documentation)\n├── LICENSE                   # Apache 2.0 license\n└── README.md                 # This file","category":"section"},{"location":"#GPU-Support","page":"Home","title":"GPU Support","text":"GPU arrays use lightweight TensorView (same as CPU), achieving 4.5x faster FFI calls than Python:\n\nCUDA: TVMFFI's CUDAExt (device detection, sync callbacks, tensor views)\nAMD ROCm: TVMFFI's AMDGPUExt\nApple Metal: TVMFFI's MetalExt\n\nAll GPU extensions automatically register cleanup hooks to prevent finalizer order issues.","category":"section"},{"location":"#Design-Philosophy","page":"Home","title":"Design Philosophy","text":"Following Linus Torvalds' principles:\n\nGood Taste: Eliminate special cases through proper data structure design\nSimplicity: Direct C API mapping with zero intermediate layers\nPractical: Solve real problems, not theoretical ones\nMemory Safety: Julia's GC + finalizers handle cleanup automatically","category":"section"},{"location":"#License","page":"Home","title":"License","text":"Licensed under the Apache License 2.0. See the source file headers for details.","category":"section"}]
}
